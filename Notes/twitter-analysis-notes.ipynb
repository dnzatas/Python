{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import credentials\n",
    "import requests\n",
    "import pandas as pd\n",
    "import tweepy as tw\n",
    "import re\n",
    "from datetime import datetime\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /Users/deniz/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to /Users/deniz/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import string\n",
    "import nltk\n",
    "from snowballstemmer import stemmer\n",
    "from collections import Counter\n",
    "nltk.download('punkt')\n",
    "nltk.download(\"stopwords\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully Authentication\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    auth = tw.OAuthHandler(credentials.API_Key, credentials.API_Key_Secret)\n",
    "    auth.set_access_token(credentials.Access_Token, credentials.Access_Token_Secret)\n",
    "    api = tw.API(auth)\n",
    "    print(\"Successfully Authentication\")\n",
    "except:\n",
    "    print(\"Failed Authentication\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def user_info(username):\n",
    "    user = api.get_user(screen_name=username)\n",
    "    user_dict={\n",
    "        'id': user.id,\n",
    "        'name': user.name,\n",
    "        'location': user.location,\n",
    "        'description': user.description,\n",
    "        'followers_count': user.followers_count,\n",
    "        'following_count': user.friends_count,\n",
    "        'create_date': (user.created_at).strftime('%d.%m.%y'),\n",
    "        'favourites_count': user.favourites_count,\n",
    "        'tweets_count: ': user.statuses_count,\n",
    "        'liked_count': user.favourites_count\n",
    "    }\n",
    "    return user_dict\n",
    "    \n",
    "user_info(\"emin_adin\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       Date                                              Tweet\n",
      "0  02/04/23  Walked whole Cybertruck production line at Gig...\n",
      "1  02/04/23  The real tragedy of @NYTimes is that their pro...\n",
      "2  02/04/23                          â™¥ï¸â™¥ï¸ @CommunityNotes â™¥ï¸â™¥ï¸\n"
     ]
    }
   ],
   "source": [
    "# Access only the most recent 200 tweets with api.user_timeline. We access tweets that includes replied\n",
    "# If want RT's include --> includerts=True\n",
    "# If want with replies -->  exclude_replies=False. \n",
    "\n",
    "def get_user_tweets(username, limit, includerts=False, excludereply=True):\n",
    "   tweets = api.user_timeline(screen_name=username, count=limit, include_rts=includerts, tweet_mode='extended', exclude_replies=excludereply)\n",
    "   tweet_list = []\n",
    "   columns = ['Date', 'Tweet']\n",
    "   for tweet in tweets:\n",
    "      tweet_list.append([(tweet.created_at).strftime('%d/%m/%y'), tweet.full_text])\n",
    "   \n",
    "   df = pd.DataFrame(tweet_list, columns=columns)\n",
    "   print(df)\n",
    "\n",
    "get_user_tweets('elonmusk', 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# You can access only the most recent 3200 tweets with tweepy.Cursor.\n",
    "# If want RT's include --> includerts=True\n",
    "# If want with replies -->  exclude_replies=False. \n",
    "\n",
    "def get_user_tweets_cursor1(username, limit, includerts=True, excludereply=False, tocsv=False):\n",
    "   tweet_list = []\n",
    "   columns = ['Date', 'Tweet', 'Likes', 'Retweet']\n",
    "   tweets = tw.Cursor(api.user_timeline, screen_name=username, count=200, include_rts=includerts, exclude_replies=excludereply, tweet_mode='extended').items(limit)\n",
    "   for tweet in tweets:\n",
    "      tweet_list.append([(tweet.created_at).strftime('%d/%m/%y'), tweet.full_text, tweet.favorite_count, tweet.retweet_count]) \n",
    "   \n",
    "   tweet_table = pd.DataFrame(tweet_list, columns=columns)\n",
    "\n",
    "   if(tocsv):\n",
    "      tweet_table.to_csv(f\"{username}.csv\", index=False)\n",
    "\n",
    "   return tweet_table\n",
    "\n",
    "get_user_tweets_cursor1('elonmusk', 20, False, True) # Only tweet that the user self-written and didn't include replies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# You can access only the most recent 3000 tweets with tweepy.Cursor.\n",
    "\n",
    "def get_user_tweets_cursor(username, limit, includerts=True, excludereply=False):\n",
    "   tweets = tw.Cursor(api.user_timeline, screen_name=username, count=200, include_rts=includerts, exclude_replies=excludereply, tweet_mode='extended').items(limit)\n",
    "   return tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_dataframe(tweets, columns=['created_at', 'full_text', 'retweet_count', 'favorite_count']):\n",
    "    columns_naming = {\n",
    "        'created_at': 'Creation Date',\n",
    "        'id': 'ID',\n",
    "        'id_str': 'ID as String',\n",
    "        'full_text': 'Full Text',\n",
    "        'truncated': 'Is Truncated',\n",
    "        'display_text_range': 'Displayed Text Range',\n",
    "        'entities': 'Entities',\n",
    "        'extended_entities': 'Extended Entities',\n",
    "        'source': 'Source',\n",
    "        'in_reply_to_status_id': 'Replied to Status ID',\n",
    "        'in_reply_to_status_id_str': 'Replied to Status ID as String',\n",
    "        'in_reply_to_user_id': 'Replied to User ID',\n",
    "        'in_reply_to_user_id_str': 'Replied to User ID as String',\n",
    "        'in_reply_to_screen_name': 'Replied to Screen Name',\n",
    "        'user': 'User',\n",
    "        'geo': 'Geo Location',\n",
    "        'coordinates': 'Coordinates',\n",
    "        'place': 'Place',\n",
    "        'contributors': 'Contributors',\n",
    "        'is_quote_status': 'Is a Quote Status',\n",
    "        'retweet_count': 'Retweet Count',\n",
    "        'favorite_count': 'Favorite Count',\n",
    "        'favorited': 'Is Favorited',\n",
    "        'retweeted': 'Is Retweeted',\n",
    "        'possibly_sensitive': 'Possibly Sensitive',\n",
    "        'lang': 'Language'\n",
    "    }\n",
    "\n",
    "    tweet_list = []\n",
    "    for tweet in tweets:\n",
    "        tweet_dict = tweet._json\n",
    "        filter_tweets = [tweet_dict[cn] for cn in columns]\n",
    "        tweet_list.append(filter_tweets)\n",
    "\n",
    "\n",
    "    columns_name = [columns_naming[key] for key in columns]\n",
    "    tweets_table = pd.DataFrame(tweet_list, columns=columns_name)\n",
    "    if 'Creation Date' in tweets_table.columns:\n",
    "        tweets_table['Creation Date'] = pd.to_datetime(tweets_table['Creation Date']).dt.strftime('%d/%m/%y')\n",
    "    return tweets_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_csv(tweets_table, username=\"tweets\"):\n",
    "    tweets_table.to_csv(f\"{username}.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_tweets(tweets):\n",
    "    en_useless_words = list(string.punctuation) + nltk.corpus.stopwords.words('english')\n",
    "    tr_useless_words = list(string.punctuation) + nltk.corpus.stopwords.words('turkish')\n",
    "    tr_filtered_text = []\n",
    "    en_filtered_text = []\n",
    "    raw_text_list = []\n",
    "    for tweet in tweets:\n",
    "        text = re.sub(r'\\w+:\\/{2}[\\d\\w-]+(\\.[\\d\\w-]+)*(?:(?:\\/[^\\s/]*))*', '', tweet._json['full_text'])\n",
    "        tweet_words = nltk.word_tokenize(text)\n",
    "        raw_text_list.extend(tweet_words)\n",
    "        if tweet.lang == 'tr':\n",
    "            tr_filtered_text.extend([word for word in tweet_words if not (word in tr_useless_words or re.match('^[^\\w]*$', word))])\n",
    "        if tweet.lang == 'en':\n",
    "            en_filtered_text.extend([word for word in tweet_words if not (word in en_useless_words or re.match('^[^\\w]*$', word))])\n",
    "    return en_filtered_text, tr_filtered_text, raw_text_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "def most_common_words(en_words, tr_words, count):\n",
    "    all_words = en_words + tr_words\n",
    "    words_count = Counter(all_words)\n",
    "    most_common = words_count.most_common()[:count]\n",
    "    \n",
    "    df = pd.DataFrame(most_common, columns=['Word', 'Count'])\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_common_words(en_words, tr_words, count):\n",
    "    all_words = en_words + tr_words\n",
    "    words_count = Counter(all_words)\n",
    "    most_common = words_count.most_common()[:count]\n",
    "    df = pd.DataFrame(most_common, columns=['Word', 'Count'])\n",
    "\n",
    "    plt.bar(df['Word'], df['Count'], color=(0.2, 0.4, 0.6, 0.6))\n",
    "    plt.title('Word Frequency')\n",
    "    plt.xlabel('Word')\n",
    "    plt.ylabel('Count')\n",
    "    plt.xticks(rotation=90)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "def most_fav_tweet(tweets):\n",
    "    most_fav_tweet = None\n",
    "    max_fav = -1\n",
    "    for tweet in tweets:\n",
    "        if tweet.favorite_count > max_fav:\n",
    "            max_fav = tweet.favorite_count\n",
    "            most_fav_tweet = tweet.full_text\n",
    "    return (most_fav_tweet, max_fav)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "def all_fonk():\n",
    "    \n",
    "    all_tweets = get_user_tweets_cursor('emin_adin', 50, False, True) # Only tweet that the user self-written and didn't include replies.\n",
    "    most_fav_tweet(all_tweets)\n",
    "\n",
    "all_fonk()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_all_tweets(screen_name, max_tweets=500, includerts=True, excludereply=False):\n",
    "    last_id = None\n",
    "\n",
    "    all_tweets = []\n",
    "    while len(all_tweets) < max_tweets:\n",
    "        new_tweets = api.user_timeline(screen_name=screen_name, count=200, max_id=last_id, include_rts=includerts, exclude_replies=excludereply)\n",
    "        if not new_tweets:\n",
    "            break\n",
    "        all_tweets.extend(new_tweets)\n",
    "        last_id = new_tweets[-1].id -1\n",
    "    return all_tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = tw.Client(bearer_token=credentials.Bearer_Token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-03-29 16:10:51+00:00 \n",
      " Åžeker ve yÃ¼ksek ÅŸekerli iÃ§ecekler, hele de fruktoz ÅŸurubu iÃ§erenler, dostunuz deÄŸildir. https://t.co/NR3jYFeLv5 \n",
      " [{'domain': {'id': '46', 'name': 'Business Taxonomy', 'description': 'Categories within Brand Verticals that narrow down the scope of Brands'}, 'entity': {'id': '1557696888568045569', 'name': 'Food & Beverage Business', 'description': 'Brands, companies, advertisers and every non-person handle with the profit intent and related to foods & beverages such as snacks, soft drinks, beers.'}}] \n",
      "\n",
      "2023-03-28 16:17:17+00:00 \n",
      " iPhone kutularÄ±nÄ± boÅŸuna saklamayÄ±n, taÅŸÄ±nÄ±nca Ã§Ã¶pe gidiyor :) â™»ï¸ https://t.co/fGuN7cdVhv \n",
      " [{'domain': {'id': '46', 'name': 'Business Taxonomy', 'description': 'Categories within Brand Verticals that narrow down the scope of Brands'}, 'entity': {'id': '1557697333571112960', 'name': 'Technology Business', 'description': 'Brands, companies, advertisers and every non-person handle with the profit intent related to softwares, apps, communication equipments, hardwares'}}, {'domain': {'id': '47', 'name': 'Brand', 'description': 'Brands and Companies'}, 'entity': {'id': '10026364281', 'name': 'Apple'}}, {'domain': {'id': '131', 'name': 'Unified Twitter Taxonomy', 'description': 'A taxonomy of user interests. '}, 'entity': {'id': '10026364281', 'name': 'Apple'}}, {'domain': {'id': '47', 'name': 'Brand', 'description': 'Brands and Companies'}, 'entity': {'id': '10026364281', 'name': 'Apple'}}, {'domain': {'id': '48', 'name': 'Product', 'description': 'Products created by Brands.  Examples: Ford Explorer, Apple iPhone.'}, 'entity': {'id': '10024011738', 'name': 'Apple - iPhone'}}, {'domain': {'id': '30', 'name': 'Entities [Entity Service]', 'description': 'Entity Service top level domain, every item that is in Entity Service should be in this domain'}, 'entity': {'id': '848920371311001600', 'name': 'Technology', 'description': 'Technology and computing'}}, {'domain': {'id': '30', 'name': 'Entities [Entity Service]', 'description': 'Entity Service top level domain, every item that is in Entity Service should be in this domain'}, 'entity': {'id': '848985956778561538', 'name': 'Mobile', 'description': 'Mobile'}}] \n",
      "\n",
      "2023-03-27 20:26:43+00:00 \n",
      " @_bilge_p_ Evet, mideyi akÅŸam erken kapatÄ±p sabah geÃ§ aÃ§mak gayet de uygun. \n",
      " [] \n",
      "\n",
      "2023-03-27 20:17:20+00:00 \n",
      " Maradonaâ€™nÄ±n kÄ±zÄ± babasÄ± antrenmanda giysin diye papatya topluyor. \n",
      "Maradona da gereÄŸini yapÄ±yor.\n",
      "ðŸ’›ðŸ¤ https://t.co/bSVDRQanub \n",
      " [{'domain': {'id': '10', 'name': 'Person', 'description': 'Named people in the world like Nelson Mandela'}, 'entity': {'id': '1011912159796719616', 'name': 'Diego Armando Maradona', 'description': 'Diego Armando Maradona'}}, {'domain': {'id': '46', 'name': 'Business Taxonomy', 'description': 'Categories within Brand Verticals that narrow down the scope of Brands'}, 'entity': {'id': '1557697289971322880', 'name': 'Sports & Fitness Business', 'description': 'Brands, companies, advertisers and every non-person handle with the profit intent related to sports nutrition, athletic apparel, sports apps, fitness venues'}}, {'domain': {'id': '60', 'name': 'Athlete', 'description': 'An athlete in the world, like Serena Williams or Lionel Messi'}, 'entity': {'id': '1011912159796719616', 'name': 'Diego Armando Maradona', 'description': 'Diego Armando Maradona'}}, {'domain': {'id': '92', 'name': 'Sports Personality', 'description': \"A Sports Personality like 'Skip Bayless'\"}, 'entity': {'id': '1011912159796719616', 'name': 'Diego Armando Maradona', 'description': 'Diego Armando Maradona'}}, {'domain': {'id': '131', 'name': 'Unified Twitter Taxonomy', 'description': 'A taxonomy of user interests. '}, 'entity': {'id': '733756536430809088', 'name': 'Soccer'}}, {'domain': {'id': '131', 'name': 'Unified Twitter Taxonomy', 'description': 'A taxonomy of user interests. '}, 'entity': {'id': '847900493514891265', 'name': 'Sports', 'description': 'Sports'}}, {'domain': {'id': '131', 'name': 'Unified Twitter Taxonomy', 'description': 'A taxonomy of user interests. '}, 'entity': {'id': '1011912159796719616', 'name': 'Diego Armando Maradona', 'description': 'Diego Armando Maradona'}}, {'domain': {'id': '131', 'name': 'Unified Twitter Taxonomy', 'description': 'A taxonomy of user interests. '}, 'entity': {'id': '1202239681422774272', 'name': 'Sports icons'}}] \n",
      "\n",
      "2023-03-26 18:16:50+00:00 \n",
      " @DrGunerSonmez Turpu sorsanÄ±z bilirdim \n",
      " [] \n",
      "\n",
      "2023-03-26 17:58:34+00:00 \n",
      " @lazycatgarfie TeÅŸekkÃ¼rler https://t.co/EsKnRvLLWM \n",
      " [] \n",
      "\n",
      "2023-03-26 17:44:06+00:00 \n",
      " Kamu spotu: kolyenizi Ã§ocuklarÄ±n eline vermeyin, Ã§ocuklarÄ±n boynuna kolye takmayÄ±n. Sonra yanlÄ±ÅŸ yerde son bulabilir. https://t.co/mD8NS0g1Qq \n",
      " [] \n",
      "\n",
      "2023-03-26 17:08:32+00:00 \n",
      " @CgdmAknArkn Temelde basit bir matematik denklemi: alÄ±nan kalori harcanan kalorinin Ã¼zerine Ã§Ä±karsa kilo alma riskiniz var. Neden kilo aldÄ±ÄŸÄ±nÄ±zÄ±n altta yatan sebebini bilmem mÃ¼mkÃ¼n deÄŸil. Diyet, aktivite, saÄŸlÄ±k durumu vs bir Ã§ok etken olabilir. \n",
      " [] \n",
      "\n",
      "2023-03-26 16:49:27+00:00 \n",
      " @neseidil HayÄ±r aslÄ±nda, doÄŸrusu sizin o ilacÄ± orada reÃ§etesiz alamamanÄ±z lazÄ±m. DoÄŸrusu budur :) \n",
      " [] \n",
      "\n",
      "2023-03-26 15:07:42+00:00 \n",
      " @DrGunerSonmez Turpun yanÄ±nda duran ÅŸeyi mi soruyorsunuz :) \n",
      " [] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# We can use Client for get User's Tweet\n",
    "\n",
    "def get_user_tweets_client(username):\n",
    "\n",
    "    user = client.get_user(username=username).data\n",
    "    userid=user.id\n",
    "\n",
    "    tweets =client.get_users_tweets(id=userid, tweet_fields=['id', 'text', 'created_at', 'context_annotations'])\n",
    "    \n",
    "    for tweet in tweets.data:\n",
    "        print((tweet.created_at).strftime('%d/%m/%y'), '\\n', tweet.text, '\\n', tweet.context_annotations, '\\n')\n",
    "\n",
    "get_user_tweets_client('emin_adin')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "    Twitter API Without Tweepy\n",
    "    Authorization and Search \n",
    "\"\"\"\n",
    "\n",
    "def create_bearer():\n",
    "    url = \"https://api.twitter.com/oauth2/token\"\n",
    "    auth = (credentials.API_Key, credentials.API_Key_Secret)\n",
    "    data = {'grant_type': 'client_credentials'}\n",
    "    response = requests.post(url, data=data, auth=auth)\n",
    "    return response.json()\n",
    "\n",
    "bearer_token = create_bearer()\n",
    "\n",
    "def get_followers_list(screen_name):\n",
    "    url = f\"https://api.twitter.com/1.1/followers/list.json?cursor=-1&screen_name={screen_name}&skip_status=true&include_user_entities=false\"\n",
    "    headers = {'Authorization': f\"{bearer_token['token_type']} {bearer_token['access_token']}\"}\n",
    "    response = requests.get(url, headers=headers)\n",
    "    return response.json()\n",
    "\n",
    "def search_tweet(query):\n",
    "        \n",
    "    url = f\"https://api.twitter.com/1.1/search/tweets.json?q={query}&result_type=popular&count=10\"\n",
    "    headers = {'Authorization': f\"{bearer_token['token_type']} {bearer_token['access_token']}\"}\n",
    "    response = requests.get(url, headers=headers)\n",
    "    return response.json()    \n",
    "\n",
    "#get_followers_list('coingirl13')\n",
    "#tweets = search_tweet('nashville')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
